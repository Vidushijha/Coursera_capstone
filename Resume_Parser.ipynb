{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "ewnuw6zwHcQu",
    "outputId": "28584861-c40b-4c2d-9a17-e571ba3e6ff6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in c:\\users\\vidushi jha\\anaconda3\\lib\\site-packages (0.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2txt\n",
    "import docx2txt\n",
    " \n",
    "def extract_text_from_doc(doc_path):\n",
    "    temp = docx2txt.process(doc_path)\n",
    "    text = [line.replace('\\t', ' ') for line in temp.split('\\n') if line]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JaW_D8BjKXS4"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 231
    },
    "colab_type": "code",
    "id": "blY3cNKUsvRA",
    "outputId": "86d2a0fb-6a1c-478a-e06b-f0175a2ecb7f"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'traindata.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-caf0e1a878ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtraining_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"traindata.json\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m   \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'traindata.json'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "import json\n",
    "\n",
    "training_data = []\n",
    "with open(\"traindata.json\",\"rb\") as f:\n",
    "  lines = f.readlines()\n",
    "  for line in lines:\n",
    "    train_data = json.loads(line)   \n",
    "    text = train_data['content']\n",
    "    entities = []\n",
    "    for annotation in train_data['annotation']:\n",
    "        point = annotation['points'][0]\n",
    "        labels = annotation['label']\n",
    "        if not isinstance(labels, list):\n",
    "            labels = [labels]\n",
    "        flag = True\n",
    "        for label in labels:\n",
    "            for x in entities:\n",
    "              if point['start'] <= x[1]:\n",
    "                flag = False\n",
    "            if flag:\n",
    "              entities.append((point['start'], point['end'] + 1 ,label))\n",
    "    training_data.append((text, {\"entities\" : entities}))\n",
    "\n",
    "TRAINING_DATA = training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NFW-9y7RU06P"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "invalid_span_tokens = re.compile(r'\\s')\n",
    "cleaned_data = []\n",
    "for text, annotations in training_data:\n",
    "    entities = annotations['entities']\n",
    "    valid_entities = []\n",
    "    for start, end, label in entities:\n",
    "        valid_start = start\n",
    "        valid_end = end\n",
    "        while valid_start < len(text) and invalid_span_tokens.match(\n",
    "                text[valid_start]):\n",
    "            valid_start += 1\n",
    "        while valid_end > 1 and invalid_span_tokens.match(\n",
    "                text[valid_end - 1]):\n",
    "            valid_end -= 1\n",
    "        valid_entities.append([valid_start, valid_end, label])\n",
    "    cleaned_data.append([text, {'entities': valid_entities}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "81XJ9LAcNcTv"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "ner = nlp.create_pipe(\"ner\")\n",
    "nlp.add_pipe(ner)\n",
    "\n",
    "for _, annotations in TRAINING_DATA:\n",
    "         for ent in annotations.get('entities'):\n",
    "            ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 799
    },
    "colab_type": "code",
    "id": "0cwRtMQPNa24",
    "outputId": "b301a85f-fc2e-4086-a649-89875b16b6fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:639: UserWarning: [W033] Training a new parser or NER using a model with no lexeme normalization table. This may degrade the performance of the model to some degree. If this is intentional or the language you're using doesn't have a normalization table, please ignore this warning. If this is surprising, make sure you have the spacy-lookups-data package installed. The languages with lexeme normalization tables are currently: da, de, el, en, id, lb, pt, ru, sr, ta, th.\n",
      "  **kwargs\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Soumya Balan\n",
      "IT SUPPORT\n",
      "\n",
      "Sulthan Bathery, Kerala, ...\" with entities \"[[4167, 4176, 'Companies worked at']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Mohammed Murtuza\n",
      "Major Incident Manager / Escalati...\" with entities \"[[7924, 8039, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Soumya Balan\n",
      "IT SUPPORT\n",
      "\n",
      "Sulthan Bathery, Kerala, ...\" with entities \"[[3913, 4370, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Krishna Prasad\n",
      "Patna, Bihar - Email me on Indeed: ...\" with entities \"[[283, 327, 'Email Address']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Siddhartha Chetri\n",
      "7 years of experience in IT Netw...\" with entities \"[[5471, 5838, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Rahul Tayade\n",
      "Global Production Support Lead, - Inf...\" with entities \"[[11131, 11235, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Pawan Nag\n",
      "Microsoft Certified System Engineer\n",
      "\n",
      "Del...\" with entities \"[[523, 562, 'Email Address']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Debasish Dasgupta\n",
      "Trainer-Finacle-Core Banking Sol...\" with entities \"[[5840, 5847, 'Companies worked at']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Puneeth R\n",
      "Escalation Specialist - HiPower Support ...\" with entities \"[[2182, 2210, 'College Name']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Sameer Kujur\n",
      "Orrisha - Email me on Indeed: indeed....\" with entities \"[[265, 307, 'Email Address']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Vinay Singhal\n",
      "New Delhi, Delhi - Email me on Indee...\" with entities \"[[937, 980, 'Email Address']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"B. Gokul\n",
      "Gokul, Uttar Pradesh - Email me on Indeed...\" with entities \"[[983, 992, 'Companies worked at']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Girish Acharya\n",
      "Technical Architect & Sr. Software ...\" with entities \"[[19383, 19402, 'Designation']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Akshay Dubey\n",
      "Actively looking for opportunity in ....\" with entities \"[[2889, 3087, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Laya A\n",
      "Cluster HR Manager - Velammal New\n",
      "\n",
      "Chennai,...\" with entities \"[[3760, 4638, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"amarjyot sodhi\n",
      "Voice and Accent Trainer :Masters i...\" with entities \"[[1130, 1174, 'Email Address']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Jaspreet Kaur\n",
      "Oceanic Consultants as a HR Executiv...\" with entities \"[[5670, 5780, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Ashish Indoriya\n",
      "Sr. Systems Engineer at Infosys Li...\" with entities \"[[3828, 3931, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Vineeth Vijayan\n",
      "\"Store Executive\" - Orange City Ho...\" with entities \"[[6994, 7350, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Paul Rajiv\n",
      "Secunderabad, Andhra Pradesh - Email me...\" with entities \"[[4729, 4733, 'Graduation Year']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Fenil Francis\n",
      "head of operation and logistics\n",
      "\n",
      "Tri...\" with entities \"[[774, 897, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Ajay Elango\n",
      "Software Engineer\n",
      "\n",
      "Bangalore City, Kar...\" with entities \"[[6930, 7494, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Praveen Bhaskar\n",
      "Program Manager (Software Delivery...\" with entities \"[[4459, 4959, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Palani S\n",
      "Senior Technology Support Executive at In...\" with entities \"[[3660, 3663, 'Graduation Year']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Priyesh Dubey\n",
      "Azure Developer with 9 Yrs 8 months ...\" with entities \"[[2733, 2742, 'Companies worked at']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Karthik G V\n",
      "Program Manager, Product Manager, Prod...\" with entities \"[[1750, 1759, 'Companies worked at']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Pavithra M\n",
      "\"Infosys\" internship\n",
      "\n",
      "Bengaluru, Karnat...\" with entities \"[[998, 1038, 'Email Address']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Sohan Dhakad\n",
      "Shivpuri, Madhya Pradesh - Email me o...\" with entities \"[[870, 893, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Dilliraja Baskaran\n",
      "Tamil Nadu - Email me on Indeed...\" with entities \"[[363, 411, 'Email Address']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Akansha Jain\n",
      "Pune, Maharashtra - Email me on Indee...\" with entities \"[[1860, 1871, 'Name']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Aarti Pimplay\n",
      "Operations Center Shift Manager (OCS...\" with entities \"[[3054, 3363, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Yogesh Ghatole\n",
      "Engineer / Electrical Supervisor, S...\" with entities \"[[2912, 3288, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Imgeeyaul Ansari\n",
      "java developer\n",
      "\n",
      "Pune, Maharashtra...\" with entities \"[[1894, 2173, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Asha Subbaiah\n",
      "(Microsoft Partner Readiness Operati...\" with entities \"[[3345, 3380, 'College Name']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Chhaya Prabhale\n",
      "Kharadi, Pune, 411014, IN - Email ...\" with entities \"[[1943, 2050, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Nitin Verma\n",
      "Assisting Microsoft Partners - Exchang...\" with entities \"[[1308, 1349, 'Email Address']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Jatin Arora\n",
      "SDET Automation Engineer, Infosys - CR...\" with entities \"[[3909, 3931, 'College Name']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Ravi Shivgond\n",
      "Bidar, Karnataka - Email me on Indee...\" with entities \"[[1341, 1384, 'Email Address']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Shraddha Achar\n",
      "Mathura, Uttar Pradesh - Email me o...\" with entities \"[[975, 1020, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Divesh Singh\n",
      "Bengaluru, Karnataka - Email me on In...\" with entities \"[[948, 1180, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Keshav Dhawale\n",
      "3 TCS Security guard Access Control...\" with entities \"[[971, 1015, 'Email Address']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Chaban kumar Debbarma\n",
      "Tripura - Email me on Indeed...\" with entities \"[[277, 328, 'Email Address']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Zaheer Uddin\n",
      "Technical Project Manager\n",
      "\n",
      "Hyderabad,...\" with entities \"[[4901, 4909, 'Location']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Kandrapu Reddy\n",
      "Senior Travel Operations (Domestic,...\" with entities \"[[4232, 4330, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Saurabh Sandhikar\n",
      "SAURABH SANDHIKAR\n",
      "\n",
      "Hyderabad, Te...\" with entities \"[[2562, 2597, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Angad Waghmare\n",
      "Pune, Maharashtra - Email me on Ind...\" with entities \"[[3878, 3937, 'Degree']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Rupesh Reddy\n",
      "Technology Consultant - EIT Services ...\" with entities \"[[6732, 6848, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Sridevi H\n",
      "Bangalore, Karnataka - Email me on Indee...\" with entities \"[[2473, 2498, 'Designation']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Rajeev Kumar\n",
      "Senior Associate Consultant - Infosys...\" with entities \"[[3982, 4412, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Gunjan Nayyar\n",
      "Hoshiarpur, Punjab - Email me on Ind...\" with entities \"[[1234, 1277, 'Email Address']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Ganesh AlalaSundaram\n",
      "A Dev-Test Professional with ...\" with entities \"[[3321, 3376, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Avani Priya\n",
      "- Email me on Indeed: indeed.com/r/Ava...\" with entities \"[[368, 409, 'Email Address']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Arpit Godha\n",
      "Senior Process Executive\n",
      "\n",
      "Jaipur, Raja...\" with entities \"[[3144, 3495, 'Skills']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n",
      "C:\\Users\\vidushi jha\\anaconda3\\lib\\site-packages\\spacy\\language.py:482: UserWarning: [W030] Some entities could not be aligned in the text \"Nida Khan\n",
      "Tech Support Executive - Teleperformance...\" with entities \"[[872, 911, 'Email Address']]\". Use `spacy.gold.biluo_tags_from_offsets(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  gold = GoldParse(doc, **gold)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': 9493.369426692108}\n",
      "{'ner': 6065.3151344938}\n",
      "{'ner': 3513.741125900381}\n",
      "{'ner': 3307.208260389254}\n",
      "{'ner': 2691.8973101926176}\n",
      "{'ner': 2795.1890996879897}\n",
      "{'ner': 3538.053716490837}\n",
      "{'ner': 1455.7594346445587}\n",
      "{'ner': 1935.2298039431994}\n",
      "{'ner': 2184.001531122229}\n",
      "{'ner': 1704.190471654981}\n",
      "{'ner': 1488.2335152511562}\n",
      "{'ner': 1342.2059711593731}\n",
      "{'ner': 1947.163308975708}\n",
      "{'ner': 1357.8855074084543}\n",
      "{'ner': 854.2722095737478}\n",
      "{'ner': 2291.330727753465}\n",
      "{'ner': 1029.8804961173994}\n",
      "{'ner': 865.8739269471082}\n",
      "{'ner': 1573.6939014621305}\n"
     ]
    }
   ],
   "source": [
    "nlp.begin_training()\n",
    "for itn in range(20):\n",
    "    random.shuffle(cleaned_data)\n",
    "    losses = {}\n",
    "    for text, annotations in cleaned_data:\n",
    "        nlp.update([text], [annotations], losses=losses)\n",
    "    print(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oHFAZEzXKd_P"
   },
   "source": [
    "# Extracting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "woEGoKX8af1x"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " VIDUSHI JHA \n",
      "\n",
      "House no. 79, Tilak Enclave, Mohan Garden, New Delhi, \n",
      "110059 | 8505991052 | vidushijha2397@gmail.com \n",
      "\n",
      "OBJECTIVE \n",
      "\n",
      "A fresher looking for a challenging role in a reputable organization to utilize \n",
      "my technical, database and management skills for the growth of the \n",
      "organization as well as to enhance my knowledge about new and emerging \n",
      "trends in the IT sector. \n",
      "\n",
      "SKILLS & ABILITIES \n",
      "\n",
      "•  TECHNICAL SKILLS \n",
      "\n",
      "Python, C/C++, Scala, Java, SQL, Data Warehousing, ETL Operation, Spark, \n",
      "Hive, Big Data, Tableau, Hadoop, AWZ, Microsoft Azure \n",
      "\n",
      "•  OPERATING SYTEMS \n",
      "\n",
      "Windows, Linux (Ubuntu, Redhat and kali) \n",
      "\n",
      "• \n",
      "\n",
      " NON-TECHNICAL SKILLS \n",
      "\n",
      "Leadership, Management, Team Spirit, Highly Motivated, Analytical \n",
      "Thinking. \n",
      "\n",
      "TRAININGS AND INTERNSHIPS \n",
      "\n",
      "June, 2018 – \n",
      "July, 2019   \n",
      "\n",
      "Dec, 2018 – Jan, \n",
      "2019  \n",
      "\n",
      "May, 2019-\n",
      "June, 2019 \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "AWS Solution Architect, Intaglio Solutions (Delhi) \n",
      "\n",
      "· In this particular training I have learnt and practiced on various AWS tools, \n",
      "services and also build various solutions on that particular platform. \n",
      "\n",
      "Data Analytics,  ADHOC Networks (Jaipur, Rajasthan) \n",
      " A training on Data Analytics on Big Data, AWS and Azure Cloud with \n",
      "Python and RHEL 7.5. \n",
      "\n",
      "  .NET Framework, Celebal Technologies (Jaipur, Rajasthan) \n",
      "\n",
      "Performed various tasks on .NET Framework using Visual Studios, C#, SQL, \n",
      "and Microsoft Azure  \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\f",
      " June, 2018 – \n",
      "July, 2019   \n",
      "\n",
      "AWS Solution Architect, Intaglio Solutions (Delhi) \n",
      "\n",
      "· In this particular training I have learnt and practiced on various AWS tools, \n",
      "services and also build various solutions on that particular platform. \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "EDUCATION \n",
      "\n",
      "2016-2010 \n",
      "\n",
      "B.Tech,  Jaipur Rajasthan, Global Institute of Technology (61% Aggregate) \n",
      "\n",
      "2015-2016 \n",
      "\n",
      "2013-2014 \n",
      "\n",
      "12th ,New Delhi, Convent of Gagan Bharti Sr, Sec. School (81%) \n",
      "\n",
      "10th ,New Delhi, Convent of Gagan Bharti Sr. Sec. School (9.8 CGPA) \n",
      "\n",
      "COMMUNICATION \n",
      "\n",
      " \n",
      "\n",
      "Apart from various Technical and Non- Technical Skills, I do have great \n",
      "communication skills and I've also hosted many public events of my school, \n",
      "college and the community. \n",
      "\n",
      "Page 2 \n",
      "\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfminer.six    \n",
    "import io\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, 'rb') as fh:\n",
    "        for page in PDFPage.get_pages(fh, caching=True, check_extractable=True):\n",
    "            resource_manager = PDFResourceManager()\n",
    "            fake_file_handle = io.StringIO()\n",
    "            converter = TextConverter(\n",
    "                                resource_manager, \n",
    "                                fake_file_handle, \n",
    "                                codec='utf-8', \n",
    "                                laparams=LAParams()\n",
    "                        )\n",
    "            page_interpreter = PDFPageInterpreter(\n",
    "                                resource_manager, \n",
    "                                converter\n",
    "                            )\n",
    "            page_interpreter.process_page(page)\n",
    "            text = fake_file_handle.getvalue()\n",
    "            yield text\n",
    "            converter.close()\n",
    "            fake_file_handle.close()\n",
    "file_path =\"Vidushi Jha.pdf\"\n",
    "text = \"\"\n",
    "for page in extract_text_from_pdf(file_path):\n",
    "    text += ' ' + page\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cugUIJ-OKdu2"
   },
   "outputs": [],
   "source": [
    "doc_to_test = nlp(text)\n",
    "d={}\n",
    "for ent in doc_to_test.ents:\n",
    "    d[ent.label_]=[]\n",
    "for ent in doc_to_test.ents:\n",
    "    d[ent.label_].append(ent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "fmDRhedncQTG",
    "outputId": "f2e92e8c-8cd2-40e1-b2fa-015f00ad50ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ORG': ['VIDUSHI JHA', 'House', 'Tilak Enclave', 'C/C++', 'Scala, Java', 'SQL', 'Data Warehousing', 'Hive', 'Big Data', 'Tableau, Hadoop', 'AWZ', 'Microsoft', 'Ubuntu', 'Analytical \\n', 'TRAININGS', 'INTERNSHIPS', 'Data Analytics', 'Big Data', 'Celebal Technologies', 'Visual Studios', 'SQL', 'Microsoft Azure', 'Global Institute of Technology', 'CGPA', 'Technical', 'Technical Skills'], 'DATE': ['no.', '110059', '8505991052', 'June', '2018', 'July', '2019', '2018', '2019', 'June', '2019', 'June', '2018', 'July', '2019', '2016-2010', '2015-2016', '2013-2014'], 'CARDINAL': ['79', '7.5', '#', '9.8'], 'PERSON': ['Mohan Garden', 'Jan', 'Intaglio Solutions', 'AWS', 'ADHOC Networks', 'AWS', 'Intaglio Solutions', 'AWS', 'Jaipur Rajasthan', 'Gagan Bharti Sr', 'Sec', 'Gagan Bharti Sr.', 'Sec'], 'GPE': ['New Delhi', 'Delhi', 'Jaipur', 'Rajasthan', 'Jaipur', 'Rajasthan', 'Delhi', 'New Delhi', 'New Delhi'], 'PERCENT': ['61%', '81%'], 'ORDINAL': ['10th'], 'PRODUCT': ['Page 2']}\n"
     ]
    }
   ],
   "source": [
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VvmIpGPhiHSM"
   },
   "source": [
    "#////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eYzc8dt9H-kQ"
   },
   "source": [
    "## Name \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_U-dxFl9H-Kn"
   },
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "matcher = Matcher(nlp.vocab)\n",
    "def extract_name(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
    "    matcher.add('NAME', None, *pattern)\n",
    "    matches = matcher(nlp_text)\n",
    "    for match_id, start, end in matches:\n",
    "        span = nlp_text[start:end]\n",
    "        return span.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gblAe1O7IJJP"
   },
   "source": [
    "## Phone Number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HFDwpYxSIJen"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_mobile_number(text):\n",
    "    phone = re.findall(re.compile(r'(?:(?:\\+?([1-9]|[0-9][0-9]|[0-9][0-9][0-9])\\s*(?:[.-]\\s*)?)?(?:\\(\\s*([2-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9])\\s*\\)|([0-9][1-9]|[0-9]1[02-9]|[2-9][02-8]1|[2-9][02-8][02-9]))\\s*(?:[.-]\\s*)?)?([2-9]1[02-9]|[2-9][02-9]1|[2-9][02-9]{2})\\s*(?:[.-]\\s*)?([0-9]{4})(?:\\s*(?:#|x\\.?|ext\\.?|extension)\\s*(\\d+))?'), text)\n",
    "    \n",
    "    if phone:\n",
    "        number = ''.join(phone[0])\n",
    "        if len(number) > 10:\n",
    "            return '+' + number\n",
    "        else:\n",
    "            return number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y3A_0HVtIL9A"
   },
   "source": [
    "## Email "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zyGeIXUZIMQg"
   },
   "outputs": [],
   "source": [
    "def extract_email(email):\n",
    "    email = re.findall(\"([^@|\\s]+@[^@]+\\.[^@|\\s]+)\", email)\n",
    "    if email:\n",
    "        try:\n",
    "            return email[0].split()[0].strip(';')\n",
    "        except IndexError:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Cri00R7I-pH"
   },
   "source": [
    "## Educaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0fBCrsT4JAZ3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\vidushi\n",
      "[nltk_data]     jha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'words'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-5982081b749e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstopwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'stopwords'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mSTOPWORDS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m EDUCATION = [  \n\u001b[0;32m      8\u001b[0m             \u001b[1;34m'BTECH'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'B.TECH'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'M.TECH'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MTECH'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bool' object has no attribute 'words'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = nltk.download('stopwords')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "EDUCATION = [  \n",
    "            'BTECH', 'B.TECH', 'M.TECH', 'MTECH', \n",
    "            'SSC', 'HSC', 'CBSE', 'ICSE', '10th', '12th'\n",
    "        ]\n",
    "\n",
    "def extract_education(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "    nlp_text = [sent.string.strip() for sent in nlp_text.sents]\n",
    "    edu = {}\n",
    "    for index, text in enumerate(nlp_text):\n",
    "        for tex in text.split():\n",
    "            tex = re.sub(r'[?|$|.|!|,]', r'', tex)\n",
    "            if tex.upper() in EDUCATION and tex not in STOPWORDS:\n",
    "                edu[tex] = text + nlp_text[index + 1]\n",
    "\n",
    "    education = []\n",
    "    education = education.astype('string')\n",
    "    for key in edu.keys():\n",
    "        year = re.search(re.compile(r'(((20|19)(\\d{2})))'), edu[key])\n",
    "        if year:\n",
    "            education.append((key, ''.join(year[0])))\n",
    "        else:\n",
    "            education.append(key)\n",
    "    return education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZzK7X5l0JXGf"
   },
   "source": [
    "## Skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-aixaMhJZ23"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'English' object has no attribute 'noun_chunks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-e7a201d07e10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_sm'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnoun_chunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnoun_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_skills\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresume_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'English' object has no attribute 'noun_chunks'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "noun_chunks = nlp.noun_chunks()\n",
    " \n",
    "def extract_skills(resume_text):\n",
    "    nlp_text = nlp(resume_text)\n",
    "    tokens = [token.text for token in nlp_text if not token.is_stop]\n",
    "    data = pd.read_csv(\"skills.csv\") \n",
    "    skills = list(data.columns.values)\n",
    "    skillset = []\n",
    "    for token in tokens:\n",
    "        if token.lower() in skills:\n",
    "            skillset.append(token)\n",
    "    for token in noun_chunks:\n",
    "        token = token.text.lower().strip()\n",
    "        if token in skills:\n",
    "            skillset.append(token)\n",
    "    \n",
    "    return [i.capitalize() for i in set([i.lower() for i in skillset])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from spacy.gold import GoldParse\n",
    "from spacy.scorer import Scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "examples = convert_dataturks_to_spacy(\"testdata.json\")\n",
    "    tp=0\n",
    "    tr=0\n",
    "    tf=0\n",
    "\n",
    "    ta=0\n",
    "    c=0        \n",
    "    for text,annot in examples:\n",
    "\n",
    "        f=open(\"resume\"+str(c)+\".txt\",\"w\")\n",
    "        doc_to_test=nlp(text)\n",
    "        d={}\n",
    "        for ent in doc_to_test.ents:\n",
    "            d[ent.label_]=[]\n",
    "        for ent in doc_to_test.ents:\n",
    "            d[ent.label_].append(ent.text)\n",
    "\n",
    "        for i in set(d.keys()):\n",
    "\n",
    "            f.write(\"\\n\\n\")\n",
    "            f.write(i +\":\"+\"\\n\")\n",
    "            for j in set(d[i]):\n",
    "                f.write(j.replace('\\n','')+\"\\n\")\n",
    "        d={}\n",
    "        for ent in doc_to_test.ents:\n",
    "            d[ent.label_]=[0,0,0,0,0,0]\n",
    "        for ent in doc_to_test.ents:\n",
    "            doc_gold_text= nlp.make_doc(text)\n",
    "            gold = GoldParse(doc_gold_text, entities=annot.get(\"entities\"))\n",
    "            y_true = [ent.label_ if ent.label_ in x else 'Not '+ent.label_ for x in gold.ner]\n",
    "            y_pred = [x.ent_type_ if x.ent_type_ ==ent.label_ else 'Not '+ent.label_ for x in doc_to_test]  \n",
    "            if(d[ent.label_][0]==0):\n",
    "                #f.write(\"For Entity \"+ent.label_+\"\\n\")   \n",
    "                #f.write(classification_report(y_true, y_pred)+\"\\n\")\n",
    "                (p,r,f,s)= precision_recall_fscore_support(y_true,y_pred,average='weighted')\n",
    "                a=accuracy_score(y_true,y_pred)\n",
    "                d[ent.label_][0]=1\n",
    "                d[ent.label_][1]+=p\n",
    "                d[ent.label_][2]+=r\n",
    "                d[ent.label_][3]+=f\n",
    "                d[ent.label_][4]+=a\n",
    "                d[ent.label_][5]+=1\n",
    "        c+=1\n",
    "    for i in d:\n",
    "        print(\"\\n For Entity \"+i+\"\\n\")\n",
    "        print(\"Accuracy : \"+str((d[i][4]/d[i][5])*100)+\"%\")\n",
    "        print(\"Precision : \"+str(d[i][1]/d[i][5]))\n",
    "        print(\"Recall : \"+str(d[i][2]/d[i][5]))\n",
    "        print(\"F-score : \"+str(d[i][3]/d[i][5]))\n",
    "train_spacy()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Resume Parser.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
